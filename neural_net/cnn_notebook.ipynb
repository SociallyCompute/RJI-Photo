{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nfrom torch.nn import Module\n# from PIL import Image\nimport torch\nimport torch.nn.functional as func\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nimport matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch import optim\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data.sampler import SubsetRandomSampler\n\nclass Net(Module):\n\n    def __init__(self, shape):\n        # possible shapes include:\n        #   4912 x 7360 x 3\n        #   4016 x 6016 x 3\n        #   2008 x 3008 x 3\n\n        super(Net, self).__init__()\n        self.first_conv = torch.nn.Conv2d(shape[2], 18, kernel_size=3, stride=1, padding=1)\n        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        self.reduction1 = torch.nn.Linear(18 * (shape[0]/2) * (shape[1]/2), 64)\n        self.reduction2 = torch.nn.Linear(64, 10) #10 is the number of possible solutions\n\n    def forward(self, data):\n        #convert to a x y x 18\n        data = func.relu(self.first_conv(data))\n        #convert to (a/2) x (y/2) x 18\n        data = self.pool(data)\n        sh = data.shape\n        #convert shape to (-1, ((a/2) x (y/2) x 18))\n        data = data.view(-1, (sh[0] * sh[1] * sh[2]))\n        data = func.relu(self.reduction1(data))\n        data = self.reduction2(data)\n        return data\n\n    def error(self):\n        return torch.nn.CrossEntropyLoss()\n\ntraining_data = []\nweights = []\n\ndef load_data(filename):\n    f = open(filename, \"r\")\n    for line in f:\n        im = Image.open(line)\n        matrix = np.array(im)\n        matrix = ((matrix[0] * matrix[1]), matrix[2])\n        training_data.append(matrix)\n    f.close()\n\ndef train_cnn():\n    training_data\n\ndef initialize_weights():\n    n = Net(training_data[0].shape)\n    for x in training_data:\n        n.forward(x)\n        \n\n# helper function to show an image\n# (used in the `plot_classes_preds` function below)\ndef matplotlib_imshow(img, one_channel=False):\n    if one_channel:\n        img = img.mean(dim=0)\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    if one_channel:\n        plt.imshow(npimg, cmap=\"Greys\")\n    else:\n        plt.imshow(np.transpose(npimg, (1, 2, 0)))"},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"import os\ndef rename(path):\n    \"\"\"Rename pictures with extension of '.JPG' to '.jpg', use only if necessary with the module being used\"\"\"\n    files = os.listdir(path)\n    for index, file in enumerate(files):\n        name = file[:-4]\n        extension = file[-4:]\n        if extension == \".JPG\":\n            os.rename(os.path.join(path, file), os.path.join(path, ''.join([name, '.jpg'])))"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"pics = {}\nnp_pics = []\ndef add_to_list_file(line, matrix):\n    pics[f] = im\n    print(im.shape)\n    np_pics.append(im.flatten())\n\ndef run_kmeans_file(matrix, clusters):\n    f = open('groupings.txt', 'a')\n    km = KMeans(n_clusters=clusters)\n    km.fit(matrix)\n    index_set = {i: np.where(km.labels_ == i)[0] for i in range(km.n_clusters)} #index of pictures in data\n    files = list(pics)\n    for i in range(len(index_set)):\n        c = index_set[i]\n        for v in c:\n            f.write(files[v] + \"\\n\")\n            print(files[v])\n        f.write('-----------')\n        print('------------')\n    f.close()\n\ndef pca_file(n):\n    all_samples = np.vstack(np_pics)\n    print(all_samples.shape)\n    pca = PCA(n_components=n)\n    return pca.fit_transform(all_samples)\n\ndef run_files():\n    count = 0\n    for inputs, labels in trainloader:\n        count = count + 1\n        line = \"../../../../..\" + line.rstrip()\n        mat3d = np.array(Image.open(line))\n        mat3d = mat3d[0::2,0::2,:]\n        mat2d = mat3d.reshape((mat3d.shape[0] * mat3d.shape[1]), mat3d.shape[2])\n        add_to_list_file(line, mat2d)\n        if(count >= 250):\n            break\n    matrix = pca_file(int(input(\"How many components would you like to compress: \")))\n    run_kmeans_file(matrix, int(input(\"How many clusters would you like to group: \")))"},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of pictures in subdirectories: 106388\n","Head of indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n","Split index: 21277\n","Size of training set: 85111, size of test set: 21277\n","trainloader: <torch.utils.data.dataloader.DataLoader object at 0x7f3e51ed5c90>\n","Classes: ['1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', 'Archive Scans', 'Fall', 'Spring', 'Summer', 'zLibrary Scans', 'zzVolunteer']\n"]}],"source":"\"\"\"define the train / validation dataset loader, using the SubsetRandomSampler for the split\"\"\"\n\ndata_dir = \"../../../../../mnt/md0/mysql-dump-economists/Archives\"#/Fall\"#/Dump\"\n\ndef load_split_train_test(datadir, valid_size = .2):\n    \n    # Helper/controller params for checking size\n    find_size_bounds = False #set to true if you are looking for min/max dims in the current set, false if you want them to be resized\n    limit_num_pictures = 1000 #set to null if you want no limit\n    \n    # define transforms to resize (look into 'Rescale'??) images to desired size and transform them into tensors\n    \"\"\" more on other transforms (RandomHorizontalFlip (\"double\" dataset\") and RandomResizedCrop (increase \n        robustness and also artificially \"increases\" our dataset) from a SO post: \n        https://stackoverflow.com/questions/50963295/pytorch-purpose-of-images-preprocessing-in-the-transfer-learning-tutorial\n    \"\"\"\n    train_transforms = transforms.Compose([transforms.Resize((425,242)),transforms.ToTensor(),]) if not find_size_bounds else transforms.Compose([transforms.ToTensor(),])\n    test_transforms = transforms.Compose([transforms.Resize((425,242)),transforms.ToTensor(),]) if not find_size_bounds else transforms.Compose([transforms.ToTensor(),])\n    \n    # load data and apply the transforms on contained pictures\n    train_data = datasets.ImageFolder(datadir, transform=train_transforms)\n    test_data = datasets.ImageFolder(datadir, transform=test_transforms)   \n    \n    maxh = 0\n    minh = 10000\n    maxw = 0\n    minw = 10000\n    if find_size_bounds:\n        try:\n            for (i, pic) in enumerate(train_data):\n                #if we are limiting pics\n                if limit_num_pictures:\n                    if i > limit_num_pictures:\n                        break\n                print(pic[0].size())\n                if pic[0].size()[1] > maxw:\n                    maxw = pic[0].size()[1]\n                elif pic[0].size()[1] < minw:\n                    minw = pic[0].size()[1]\n\n                if pic[0].size()[2] > maxh:\n                    maxh = pic[0].size()[2]\n                elif pic[0].size()[2] < minh:\n                    minh = pic[0].size()[2]\n        except Exception as e:\n            print(e)\n            print(\"error occurred on pic {} number {}\".format(pic, i))\n    \n        print(\"Max/min width: {} {}\".format(maxw, minw))\n        print(\"Max/min height: {} {}\".format(maxh, minh))\n    \n    num_pictures = len(train_data)\n    print(\"Number of pictures in subdirectories: {}\".format(num_pictures))\n    \n    # Shuffle pictures and split training set\n    indices = list(range(num_pictures))\n    print(\"Head of indices: {}\".format(indices[:10]))\n    \n    split = int(np.floor(valid_size * num_pictures))\n    print(\"Split index: {}\".format(split))\n    \n    # may be unnecessary with the choice of sampler below\n#     np.random.shuffle(indices)\n#     print(\"Head of shuffled indices: {}\".format(indices[:10]))\n    \n    train_idx, test_idx = indices[split:], indices[:split]\n    print(\"Size of training set: {}, size of test set: {}\".format(len(train_idx), len(test_idx)))\n    \n    # Define samplers that sample elements randomly without replacement\n    train_sampler = SubsetRandomSampler(train_idx)\n    test_sampler = SubsetRandomSampler(test_idx)\n    \n    # Define data loaders, which allow batching the data, shuffling the data, and \n    #     loading the data in parallel using multiprocessing workers\n    trainloader = torch.utils.data.DataLoader(train_data,\n                   sampler=train_sampler, batch_size=1, num_workers=4)\n    testloader = torch.utils.data.DataLoader(test_data,\n                   sampler=test_sampler, batch_size=1, num_workers=4)\n    return trainloader, testloader\n# rename(\"/mnt/md0/mysql-dump-economists/Archives/1999/Fall/Dump/Beard, Rebecca\")\ntrainloader, testloader = load_split_train_test(data_dir, .2)\nprint(\"trainloader: {}\".format(trainloader))\nprint(\"Classes: {}\".format(trainloader.dataset.classes))\nrun_files()"},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",")\n"]},{"data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Sequential(\n","    (0): Linear(in_features=2048, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Dropout(p=0.2, inplace=False)\n","    (3): Linear(in_features=512, out_features=10, bias=True)\n","    (4): LogSoftmax()\n","  )\n",")"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":"\"\"\"Not necessary to run, just curious. Loads a pretrained model, printing the model just to see \n    the layer architecture of the ResNet model.\n    List of other models: https://pytorch.org/docs/stable/torchvision/models.html\"\"\"\n# enable CUDA tensor types, that implement the same function as CPU tensors, but they \n#     utilize GPUs for computation (if the device we are on has GPUs)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = models.resnet50(pretrained=True)\nprint(model)\n\n\"\"\"\nFirst, we have to freeze the pre-trained layers, so we don’t backprop through them during training. \nThen, we re-define the final fully-connected the layer, the one that we’ll train with our images. \nWe also create the criterion (the loss function) and pick an optimizer (Adam in this case) and learning rate.\n\"\"\"\n\nfor param in model.parameters():\n    param.requires_grad = False\n    \nmodel.fc = nn.Sequential(nn.Linear(2048, 512),\n                                 nn.ReLU(),\n                                 nn.Dropout(0.2),\n                                 nn.Linear(512, 10),\n                                 nn.LogSoftmax(dim=1))\ncriterion = nn.NLLLoss()\noptimizer = optim.Adam(model.fc.parameters(), lr=0.003)\nmodel.to(device)"},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"ename":"RuntimeError","evalue":"Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at /pytorch/aten/src/THNN/generic/ClassNLLCriterion.c:97","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-e02070bbeefe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mlogps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/rji/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/rji/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/rji/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1836\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1837\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1838\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1839\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at /pytorch/aten/src/THNN/generic/ClassNLLCriterion.c:97"]}],"source":"\"\"\"\nYou load the batches of images and do the feed forward loop. \nThen calculate the loss function, and use the optimizer to apply gradient descent in back-propagation.\nMost of the code below deals with displaying the losses and calculate accuracy every 10 batches, \n    so you get an update while training is running. \nDuring validation, don’t forget to set the model to eval() mode, and then back to train() once you’re finished.\n\"\"\"\nepochs = 1\nsteps = 0\nrunning_loss = 0\nprint_every = 10\ntrain_losses, test_losses = [], []\nfor epoch in range(epochs):\n    for inputs, labels in trainloader:\n        \n        if steps > 10:\n            break\n        steps += 1\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        logps = model.forward(inputs)\n        loss = criterion(logps, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n        \n        if steps % print_every == 0:\n            test_loss = 0\n            accuracy = 0\n            model.eval()\n            with torch.no_grad():\n                for inputs, labels in testloader:\n                    inputs, labels = inputs.to(device), labels.to(device)\n                    logps = model.forward(inputs)\n                    batch_loss = criterion(logps, labels)\n                    test_loss += batch_loss.item()\n                    \n                    ps = torch.exp(logps)\n                    top_p, top_class = ps.topk(1, dim=1)\n                    equals = top_class == labels.view(*top_class.shape) \n                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n            train_losses.append(running_loss/len(trainloader))\n            test_losses.append(test_loss/len(testloader))                    \n            print(f\"Epoch {epoch+1}/{epochs}.. \"\n                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n            running_loss = 0\n            model.train()\ntorch.save(model, 'cnn_classifier_model.pth')"},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"image/png":{"height":248,"width":385},"needs_background":"light"},"output_type":"display_data"}],"source":"\"\"\"plot the training and validation losses\"\"\"\nplt.plot(train_losses, label='Training loss')\nplt.plot(test_losses, label='Validation loss')\nplt.legend(frameon=False)\nplt.show()"},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Sequential(\n","    (0): Linear(in_features=2048, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Dropout(p=0.2, inplace=False)\n","    (3): Linear(in_features=512, out_features=10, bias=True)\n","    (4): LogSoftmax()\n","  )\n",")"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":"\"\"\" again we check for GPU availability, load the model and put it into evaluation mode \n    (so parameters are not altered)\"\"\"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel=torch.load('cnn_classifier_model.pth')\nmodel.eval()"},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":"\"\"\"function that predicts the class of a specific image\"\"\"\ndef predict_image(image):\n    image_tensor = test_transforms(image).float()\n    image_tensor = image_tensor.unsqueeze_(0)\n    input = Variable(image_tensor)\n    input = input.to(device)\n    output = model(input)\n    index = output.data.cpu().numpy().argmax()\n    return index"},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":"\"\"\"function that will pick a number of random images from the dataset folders\"\"\"\ndef get_random_images(num):\n    data = datasets.ImageFolder(data_dir, transform=test_transforms)\n    classes = data.classes\n    indices = list(range(len(data)))\n    np.random.shuffle(indices)\n    idx = indices[:num]\n    from torch.utils.data.sampler import SubsetRandomSampler\n    sampler = SubsetRandomSampler(idx)\n    loader = torch.utils.data.DataLoader(data, \n                   sampler=sampler, batch_size=num)\n    dataiter = iter(loader)\n    images, labels = dataiter.next()\n    return images, labels"},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'test_transforms' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-314baf59eda4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"demo the prediction function, I get the random image sample, predict them and display the results\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mto_pil\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToPILImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_random_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-24-c30455dfcf2a>\u001b[0m in \u001b[0;36mget_random_images\u001b[0;34m(num)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"function that will pick a number of random images from the dataset folders\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_random_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'test_transforms' is not defined"]}],"source":"\"\"\"demo the prediction function, I get the random image sample, predict them and display the results\"\"\"\nto_pil = transforms.ToPILImage()\nimages, labels = get_random_images(5)\nfig=plt.figure(figsize=(10,10))\nfor ii in range(len(images)):\n    image = to_pil(images[ii])\n    index = predict_image(image)\n    sub = fig.add_subplot(1, len(images), ii+1)\n    res = int(labels[ii]) == index\n    sub.set_title(str(classes[index]) + \":\" + str(res))\n    plt.axis('off')\n    plt.imshow(image)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}