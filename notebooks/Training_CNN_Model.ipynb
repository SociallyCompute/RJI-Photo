{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, pandas as pd, numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, ConcatDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import transform\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pds\n",
    "\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import torchvision\n",
    "from torchvision import transforms, utils, models\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 48\n",
    "output_nodes = 1\n",
    "AVA_NP_REGRESS_FILES = '/media/matt/New Volume/ava/np_regress_files/'\n",
    "PATH = 'modifiedResNet.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Our modified version with changing the final layer (using CNN as classifier)\n",
    "\"\"\"\n",
    "class modifiedResNet(nn.Module):\n",
    "    def __init__(self,num_outputs,existing_model=None,frozen=False):\n",
    "        super(modifiedResNet, self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "        self.existing_model = existing_model\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        if(frozen):\n",
    "            for param in self.resnet.parameters():\n",
    "                param.requires_grad = False\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.resnet(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(data_filepath, idx):\n",
    "    dataset_list = []\n",
    "    for i,f in enumerate(os.listdir(data_filepath), idx):\n",
    "        data = np.load(data_filepath + f)\n",
    "        if (i - idx) > 1023:\n",
    "            break\n",
    "        tensor_x = torch.Tensor(data['x'])\n",
    "        tensor_x = torch.unsqueeze(tensor_x, 0)\n",
    "        # print(tensor_x.size())\n",
    "        tensor_y = torch.Tensor(data['y'])\n",
    "        tensor_y = torch.unsqueeze(tensor_y, 0)\n",
    "        # print(tensor_y.size())\n",
    "\n",
    "        dataset_list.append(TensorDataset(tensor_x,tensor_y))\n",
    "\n",
    "    dataset = ConcatDataset(dataset_list)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NEW Train method\n",
    "\"\"\"\n",
    "def train_model(model,save_filepath,training_loader,validation_loader, epochs):\n",
    "\n",
    "    epochs_list = []\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "    training_len = len(training_loader.dataset)\n",
    "    validation_len = len(validation_loader.dataset)\n",
    "\n",
    "    data_loaders = {\"train\": training_loader, \"val\": validation_loader}\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_func = nn.MSELoss() #nn.CrossEntropyLoss()\n",
    "\n",
    "    # training and testing\n",
    "    for epoch in tqdm(range(epochs), position=0, leave=True):\n",
    "\n",
    "        train_loss = 0.0\n",
    "        val_loss = 0.0\n",
    "        temp_loss = 100000000000000.0\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train(True)\n",
    "            else:\n",
    "                model.train(False)\n",
    "\n",
    "            running_loss = 0.0\n",
    "            for i, (x, y) in enumerate(data_loaders[phase]):\n",
    "                output = model(x)\n",
    "                o = torch.squeeze(output).type(torch.FloatTensor)\n",
    "                l = torch.squeeze(y).type(torch.FloatTensor)\n",
    "#                 if epoch % 10 == 0:\n",
    "#                     print(o, l)\n",
    "                loss = loss_func(o, l)\n",
    "                optimizer.zero_grad()           \n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()                                      \n",
    "\n",
    "                running_loss += loss.item()\n",
    "            \n",
    "            if phase == 'train':\n",
    "                train_loss = running_loss\n",
    "            else:\n",
    "                val_loss = running_loss\n",
    "        if epoch % 10 == 0:\n",
    "            print('[%d, %5d] train loss: %.6f val loss: %.6f' % (epoch + 1, i + 1, train_loss, val_loss))\n",
    "        if val_loss < temp_loss:\n",
    "            torch.save(model, save_filepath)\n",
    "            temp_loss = val_loss\n",
    "        epochs_list.append(epoch)\n",
    "        train_loss_list.append(train_loss)\n",
    "        val_loss_list.append(val_loss)\n",
    "    \n",
    "    loss_df = pds.DataFrame(\n",
    "        {\n",
    "            'epoch': epochs_list,\n",
    "            'training loss': train_loss_list,\n",
    "            'validation loss': val_loss_list\n",
    "        }\n",
    "    )\n",
    "    # Writing loss csv, change path to whatever you want to name it\n",
    "    loss_df.to_csv('loss.csv', index=None)\n",
    "    return train_loss_list, val_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d34afe6ae21f46ba822c0c6f2b52bb5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    22] train loss: 60.847301 val loss: 2521.596123\n",
      "[11,    22] train loss: 7.381043 val loss: 8.716837\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "model = modifiedResNet(output_nodes)\n",
    "\n",
    "training_dataset = get_dataset(AVA_NP_REGRESS_FILES,0)\n",
    "training_loader = DataLoader(dataset=training_dataset,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "validation_dataset = get_dataset(AVA_NP_REGRESS_FILES,1024)\n",
    "validation_loader = DataLoader(dataset=validation_dataset,batch_size=batch_size)\n",
    "\n",
    "training_loss, validation_loss = train_model(model,PATH,training_loader,validation_loader,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "fig.tight_layout()\n",
    "ax[0,0].plot(range(epochs), validation_loss)\n",
    "ax[0,0].set_title('Validation Loss')\n",
    "ax[0,0].set_ylabel('Loss')\n",
    "ax[0,0].set_xlabel('Epoch')\n",
    "\n",
    "ax[0,1].plot(range(epochs), training_loss)\n",
    "ax[0,1].set_title('Training Loss')\n",
    "ax[0,1].set_ylabel('Loss')\n",
    "ax[0,1].set_xlabel('Epoch')\n",
    "\n",
    "\n",
    "# ax[1,0].plot(np.arange(v_labels_list.shape[0]), v_labels_list[:,0], color='blue')\n",
    "# ax[1,0].plot(np.arange(v_labels_list.shape[0]), v_output_list[:,0], color='red')\n",
    "# ax[1,0].set_title('Validation Amps per Sample')\n",
    "# ax[1,0].set_ylabel('Amp')\n",
    "# ax[1,0].set_xlabel('Sample')\n",
    "\n",
    "# ax[1,1].plot(np.arange(t_labels_list.shape[0]), t_labels_list[:,0], color='blue')\n",
    "# ax[1,1].plot(np.arange(t_labels_list.shape[0]), t_output_list[:,0], color='red')\n",
    "# ax[1,1].set_title('Training Amps per Sample')\n",
    "# ax[1,1].set_ylabel('Amp')\n",
    "# ax[1,1].set_xlabel('Sample')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
