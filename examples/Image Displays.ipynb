{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, pandas as pd, numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import transform\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import torchvision\n",
    "from torchvision import transforms, utils, models\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AVAImagesDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.ava_frame = pd.read_csv(csv_file, sep=\" \", header=None)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ava_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir, str(self.ava_frame.iloc[idx, 0]) + '.jpg')\n",
    "        if not os.path.isfile(img_name):\n",
    "            return None\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        # classes = np.array([self.ava_frame.iloc[idx, 2:12]])\n",
    "        classes_txt = self.ava_frame.iloc[idx, 12:14]\n",
    "        classes = np.zeros((66))\n",
    "        # print(classes_txt)\n",
    "        for c in classes_txt:\n",
    "            # print(c)\n",
    "            if c != 0:\n",
    "                classes[(int(c) - 1)] = 1\n",
    "        classes = classes.astype('float').reshape(-1, 66)\n",
    "        # print(classes)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            classes = torch.from_numpy(classes)\n",
    "            # print(classes)\n",
    "        sample = {'image': image, 'classes': classes}\n",
    "        print(sample['image'])\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# mo_dataset = AVAImagesDataset(csv_file='/media/matt/New Volume/ava/cleanedlabels.txt', \n",
    "#                                root_dir='/media/matt/New Volume/missourian_pics/2017/Fall/Dump/Compton, Nate/',\n",
    "#                                transform=transforms.Compose([\n",
    "#                                    transforms.Resize(256), \n",
    "#                                    transforms.CenterCrop(224), \n",
    "#                                    transforms.ToTensor(), \n",
    "#                                    transforms.Normalize(\n",
    "#                                        mean=[0.485, 0.456, 0.406], \n",
    "#                                        std=[0.229, 0.224, 0.225])\n",
    "#                                        ]))\n",
    "\n",
    "# dataset_size = len(mo_dataset)\n",
    "\n",
    "# dataloader = DataLoader(mo_dataset, batch_size=1)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform=transforms.Compose([transforms.Resize(256), \n",
    "                              transforms.CenterCrop(224), \n",
    "                              transforms.ToTensor(), \n",
    "                              transforms.Normalize(\n",
    "                                mean=[0.485, 0.456, 0.406], \n",
    "                                std=[0.229, 0.224, 0.225])\n",
    "                              ])\n",
    "\n",
    "def image_loader(image_name):\n",
    "    \"\"\"load image, returns cuda tensor\"\"\"\n",
    "    image = Image.open(image_name)\n",
    "    image = transform(image).float()\n",
    "    return image.to(device) #assumes that you're using GPU\n",
    "\n",
    "model_ft = models.resnet50(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "# model_ft.fc = nn.Linear(num_ftrs, 10)\n",
    "model_ft.fc = nn.Linear(num_ftrs, 66)\n",
    "\n",
    "# model_ft.load_state_dict(torch.load(\"../common/Nov17_r50_6ep_32batch.pt\"))\n",
    "model_ft.load_state_dict(torch.load(\"../common/Nov18_r50_20ep_classifier.pt\"))\n",
    "model_ft.eval()\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# image = image_loader('/media/matt/New Volume/missourian_pics/2017/Fall/Dump/Compton, Nate/20170824_MUfootballpractice_NC/20170824_mufootball_NC_001.JPG')\n",
    "image = image_loader('/media/matt/New Volume/missourian_pics/2017/Fall/Dump/Compton, Nate/20170824_MUfootballpractice_NC/20170824_mufootball_NC_008.JPG')\n",
    "output = model_ft(image[None, ...])\n",
    "_, preds = torch.max(output, 1)\n",
    "# print(preds[0].item())\n",
    "print(preds[0].item() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
